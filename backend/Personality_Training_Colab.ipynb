{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Personality Prediction Model Training\n",
    "\n",
    "This notebook trains a BERT-based personality prediction model using the Big Five personality traits.\n",
    "\n",
    "## Setup\n",
    "1. **Runtime**: Go to Runtime â†’ Change runtime type â†’ GPU (T4, A100, or V100)\n",
    "2. **Run all cells** in order\n",
    "3. **Download** the trained model at the end\n",
    "\n",
    "**Estimated time**: 15-30 minutes on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch datasets accelerate tensorboard matplotlib seaborn scikit-learn\n",
    "!pip install --upgrade numpy<2  # Fix numpy compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU detected. Training will be slower on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    TrainingArguments, Trainer, \n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "class TrainingConfig:\n",
    "    def __init__(self):\n",
    "        # Model settings\n",
    "        self.model_name = \"distilbert-base-uncased\"  # Faster than BERT\n",
    "        self.max_length = 256\n",
    "        self.hidden_size = 768\n",
    "        self.num_labels = 5  # Big Five traits\n",
    "        self.dropout = 0.1\n",
    "        \n",
    "        # Training settings\n",
    "        self.batch_size = 32  # Larger batch for GPU\n",
    "        self.learning_rate = 3e-5\n",
    "        self.num_epochs = 3\n",
    "        self.warmup_steps = 500\n",
    "        self.weight_decay = 0.01\n",
    "        \n",
    "        # Dataset settings\n",
    "        self.dataset_name = \"essays_big5\"\n",
    "        self.train_split = 0.8\n",
    "        self.val_split = 0.1\n",
    "        self.test_split = 0.1\n",
    "        \n",
    "        # Evaluation settings\n",
    "        self.eval_steps = 100\n",
    "        self.logging_steps = 50\n",
    "        self.save_steps = 500\n",
    "        self.early_stopping_patience = 2\n",
    "        \n",
    "        # Device\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.mixed_precision = torch.cuda.is_available()\n",
    "        \n",
    "        # Reproducibility\n",
    "        self.seed = 42\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return {k: v for k, v in self.__dict__.items() if not k.startswith('_')}\n",
    "\n",
    "config = TrainingConfig()\n",
    "print(f\"âœ… Training config created. Using device: {config.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load essays-big5 dataset\n",
    "print(\"ðŸ“Š Loading essays-big5 dataset from Hugging Face...\")\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    ds = load_dataset(\"jingjietan/essays-big5\")\n",
    "    df = ds['train'].to_pandas()\n",
    "    \n",
    "    print(f\"ðŸ“ˆ Dataset loaded: {len(df)} samples\")\n",
    "    print(f\"ðŸ“‹ Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check the first few rows\n",
    "    display(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading dataset: {e}\")\n",
    "    print(\"ðŸ”„ Creating synthetic dataset instead...\")\n",
    "    \n",
    "    # Create synthetic dataset as fallback\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(2000):\n",
    "        text = f\"This is sample text {i} for personality analysis. It contains various personality indicators.\"\n",
    "        personality = np.random.normal(0.5, 0.15, 5)\n",
    "        personality = np.clip(personality, 0, 1)\n",
    "        \n",
    "        texts.append(text)\n",
    "        labels.append(personality)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'openness': [l[0] for l in labels],\n",
    "        'conscientiousness': [l[1] for l in labels],\n",
    "        'extraversion': [l[2] for l in labels],\n",
    "        'agreeableness': [l[3] for l in labels],\n",
    "        'neuroticism': [l[4] for l in labels]\n",
    "    })\n",
    "    \n",
    "    print(f\"ðŸ“ˆ Synthetic dataset created: {len(df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset\n",
    "print(\"ðŸ”§ Processing dataset...\")\n",
    "\n",
    "# Column mapping for essays-big5 dataset\n",
    "column_mapping = {\n",
    "    'O': 'openness',\n",
    "    'C': 'conscientiousness', \n",
    "    'E': 'extraversion',\n",
    "    'A': 'agreeableness',\n",
    "    'N': 'neuroticism'\n",
    "}\n",
    "\n",
    "# Apply column mapping\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Ensure we have the required columns\n",
    "big_five_traits = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "\n",
    "# Process personality scores\n",
    "for trait in big_five_traits:\n",
    "    if trait in df.columns:\n",
    "        df[trait] = pd.to_numeric(df[trait], errors='coerce')\n",
    "        \n",
    "        # Convert binary to continuous if needed\n",
    "        unique_values = df[trait].dropna().unique()\n",
    "        if len(unique_values) <= 2 and set(unique_values).issubset({0, 1}):\n",
    "            print(f\"ðŸ”„ Converting {trait} from binary to continuous scores\")\n",
    "            df[trait] = df[trait].apply(lambda x: \n",
    "                np.random.uniform(0.2, 0.4) if x == 0 else \n",
    "                np.random.uniform(0.6, 0.8) if x == 1 else 0.5)\n",
    "    else:\n",
    "        df[trait] = 0.5  # Default neutral value\n",
    "\n",
    "# Filter out short texts\n",
    "df = df[df['text'].str.len() > 50]\n",
    "\n",
    "# Select final columns\n",
    "df = df[['text'] + big_five_traits]\n",
    "\n",
    "print(f\"âœ… Dataset processed: {len(df)} samples\")\n",
    "print(f\"ðŸ“Š Text length - Mean: {df['text'].str.len().mean():.1f}, Median: {df['text'].str.len().median():.1f}\")\n",
    "\n",
    "# Show personality trait statistics\n",
    "for trait in big_five_traits:\n",
    "    mean_score = df[trait].mean()\n",
    "    std_score = df[trait].std()\n",
    "    print(f\"ðŸŽ¯ {trait.capitalize()}: Mean={mean_score:.3f}, Std={std_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class PersonalityDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "print(\"âœ… Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Model definition\nclass PersonalityModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        \n        # Handle both custom config and transformers config objects\n        if hasattr(config, 'model_name'):\n            model_name = config.model_name\n            hidden_size = config.hidden_size\n            dropout = config.dropout\n            num_labels = config.num_labels\n        else:\n            # If it's a transformers config object, use defaults\n            model_name = \"distilbert-base-uncased\"\n            hidden_size = getattr(config, 'hidden_size', 768)\n            dropout = getattr(config, 'dropout', 0.1)\n            num_labels = getattr(config, 'num_labels', 5)\n        \n        # Load pre-trained model\n        self.bert = AutoModel.from_pretrained(model_name)\n        \n        # Classification head\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(hidden_size, num_labels)\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        \n        loss = None\n        if labels is not None:\n            loss_fn = nn.MSELoss()\n            loss = loss_fn(logits, labels)\n        \n        return {\n            'loss': loss,\n            'logits': logits\n        }\n\nprint(\"âœ… Model class defined\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "print(\"ðŸ”§ Preparing data for training...\")\n",
    "\n",
    "# Extract texts and labels\n",
    "texts = df['text'].tolist()\n",
    "labels = df[big_five_traits].values.tolist()\n",
    "\n",
    "# Split dataset\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=config.test_split, random_state=config.seed\n",
    ")\n",
    "\n",
    "val_size = config.val_split / (1 - config.test_split)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=val_size, random_state=config.seed\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Dataset split:\")\n",
    "print(f\"   Train: {len(train_texts)} samples\")\n",
    "print(f\"   Validation: {len(val_texts)} samples\")\n",
    "print(f\"   Test: {len(test_texts)} samples\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PersonalityDataset(train_texts, train_labels, tokenizer, config.max_length)\n",
    "val_dataset = PersonalityDataset(val_texts, val_labels, tokenizer, config.max_length)\n",
    "test_dataset = PersonalityDataset(test_texts, test_labels, tokenizer, config.max_length)\n",
    "\n",
    "print(\"âœ… Data preparation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize model\nprint(\"ðŸ¤– Initializing model...\")\n\n# Use the training config (not model config)\nmodel = PersonalityModel(config)  # This should be the TrainingConfig instance\nmodel.to(config.device)\n\nprint(f\"âœ… Model initialized and moved to {config.device}\")\nprint(f\"ðŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics computation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Calculate metrics for each personality trait\n",
    "    metrics = {}\n",
    "    trait_names = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "    \n",
    "    for i, trait in enumerate(trait_names):\n",
    "        pred_trait = predictions[:, i]\n",
    "        true_trait = labels[:, i]\n",
    "        \n",
    "        mse = mean_squared_error(true_trait, pred_trait)\n",
    "        mae = mean_absolute_error(true_trait, pred_trait)\n",
    "        r2 = r2_score(true_trait, pred_trait)\n",
    "        \n",
    "        metrics[f'{trait}_mse'] = mse\n",
    "        metrics[f'{trait}_mae'] = mae\n",
    "        metrics[f'{trait}_r2'] = r2\n",
    "    \n",
    "    # Overall metrics\n",
    "    overall_mse = mean_squared_error(labels.flatten(), predictions.flatten())\n",
    "    overall_mae = mean_absolute_error(labels.flatten(), predictions.flatten())\n",
    "    overall_r2 = r2_score(labels.flatten(), predictions.flatten())\n",
    "    \n",
    "    metrics.update({\n",
    "        'overall_mse': overall_mse,\n",
    "        'overall_mae': overall_mae,\n",
    "        'overall_r2': overall_r2\n",
    "    })\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"âœ… Metrics function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "print(\"ðŸš€ Setting up training...\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./personality_model',\n",
    "    num_train_epochs=config.num_epochs,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    warmup_steps=config.warmup_steps,\n",
    "    weight_decay=config.weight_decay,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=config.logging_steps,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=config.eval_steps,\n",
    "    save_steps=config.save_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_overall_r2\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=3,\n",
    "    fp16=config.mixed_precision,\n",
    "    learning_rate=config.learning_rate,\n",
    "    report_to=None,  # Disable wandb\n",
    "    dataloader_pin_memory=False,  # Helps with Colab\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=config.early_stopping_patience)]\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"ðŸŽ¯ Starting training...\")\n",
    "print(\"â±ï¸  This may take 15-30 minutes depending on your GPU\")\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "    print(\"\\nðŸŽ‰ Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Training failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"ðŸ“Š Evaluating on test set...\")\n",
    "\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(\"\\nðŸ“ˆ Test Results:\")\n",
    "for key, value in test_results.items():\n",
    "    if 'r2' in key or 'mse' in key or 'mae' in key:\n",
    "        print(f\"   {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "print(\"ðŸ’¾ Saving trained model...\")\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained('./personality_model_final')\n",
    "tokenizer.save_pretrained('./personality_model_final')\n",
    "\n",
    "# Save configuration\n",
    "with open('./personality_model_final/training_config.json', 'w') as f:\n",
    "    json.dump(config.to_dict(), f, indent=2)\n",
    "\n",
    "print(\"âœ… Model saved to './personality_model_final'\")\n",
    "\n",
    "# Create a zip file for easy download\n",
    "import shutil\n",
    "shutil.make_archive('personality_model_trained', 'zip', './personality_model_final')\n",
    "print(\"ðŸ“¦ Model packaged as 'personality_model_trained.zip'\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Next steps:\")\n",
    "print(\"1. Download the 'personality_model_trained.zip' file\")\n",
    "print(\"2. Extract it to your local models/ directory\")\n",
    "print(\"3. Update your Flask backend to use the trained model\")\n",
    "print(\"4. Set use_mock_model = False in model_loader.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "print(\"ðŸ§ª Testing trained model...\")\n",
    "\n",
    "# Test with a sample text\n",
    "test_text = \"I love meeting new people and exploring creative projects. I'm always organized and plan everything in advance.\"\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=config.max_length)\n",
    "inputs = {k: v.to(config.device) for k, v in inputs.items()}\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs['logits'].cpu().numpy()[0]\n",
    "\n",
    "# Display results\n",
    "trait_names = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']\n",
    "print(f\"\\nðŸŽ¯ Personality Analysis for: '{test_text}'\")\n",
    "print(\"â”\" * 60)\n",
    "for trait, score in zip(trait_names, predictions):\n",
    "    print(f\"ðŸ“Š {trait:15}: {score:.3f} ({'High' if score > 0.6 else 'Medium' if score > 0.4 else 'Low'})\")\n",
    "\n",
    "print(\"\\nâœ… Model test completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}